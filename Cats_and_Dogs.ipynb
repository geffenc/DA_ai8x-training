{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b261e12b",
   "metadata": {},
   "source": [
    "# Cats and Dogs Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66236c4",
   "metadata": {},
   "source": [
    "This notebook will train, quantize, and synthesis the Cats and Dogs example. We want to use this example to show that a high test set accuracy does not guarantee a high accuracy on the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dc191",
   "metadata": {},
   "source": [
    "### Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "660421b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "\n",
    "try:\n",
    "    import tensorboard  # pylint: disable=import-error\n",
    "    import tensorflow  # pylint: disable=import-error\n",
    "    tensorflow.io.gfile = tensorboard.compat.tensorflow_stub.io.gfile\n",
    "except (ModuleNotFoundError, AttributeError):\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchnet.meter as tnt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import nnplot\n",
    "import operator\n",
    "import distiller\n",
    "import distiller.apputils as apputils\n",
    "from distiller.data_loggers import PythonLogger, TensorBoardLogger\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'models/')\n",
    "sys.path.insert(1, 'distiller/')\n",
    "sys.path.insert(2, 'datasets/')\n",
    "\n",
    "from cats_and_dogs import *\n",
    "\n",
    "mod = importlib.import_module(\"cat-dog_net\")\n",
    "\n",
    "import ai8x\n",
    "%matplotlib inline\n",
    "\n",
    "# Logger handle\n",
    "msglogger = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fa465",
   "metadata": {},
   "source": [
    "## Define Training Configurations (args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e36ccb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cats_and_dogs\"\n",
    "dataset_fn = cats_and_dogs_get_datasets\n",
    "num_classes = 2\n",
    "model_name = \"catdognet\"\n",
    "dimensions = (3,128,128)\n",
    "workers = 4\n",
    "batch_size = 32\n",
    "validation_split = 0.1\n",
    "log_prefix = \"train_log\"\n",
    "log_dir = \"jupyter_logging\"\n",
    "data_path = \"../Datasets/cats_and_dogs/\"\n",
    "deterministic = True\n",
    "print_freq = 100\n",
    "labels = ('dog', 'cat')\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebbe33",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3fbec67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, act_mode_8bit):\n",
    "        self.act_mode_8bit = act_mode_8bit\n",
    "        self.truncate_testset = False\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f8575a",
   "metadata": {},
   "source": [
    "## Set up the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c84b777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log file for this run: /home/geffencooper/Model_Development/ai8x-training/jupyter_logging/train_log___2022.06.21-174615/train_log___2022.06.21-174615.log\n",
      "dataset_name:cats_and_dogs\n",
      "dataset_fn=<function cats_and_dogs_get_datasets at 0x7fcef0358820>\n",
      "num_classes=2\n",
      "model_name=catdognet\n",
      "dimensions=(3, 128, 128)\n",
      "batch_size=32\n",
      "validation_split=0.1\n",
      "lr=0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "Logging to TensorBoard - remember to execute the server:\n",
      "> tensorboard --logdir='./logs'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msglogger = apputils.config_pylogger('logging.conf', log_prefix,\n",
    "                                        log_dir)\n",
    "\n",
    "# Log various details about the execution environment.  It is sometimes useful\n",
    "# to refer to past experiment executions and this information may be useful.\n",
    "apputils.log_execution_env_state(None, msglogger.logdir)\n",
    "msglogger.debug(\"Distiller: %s\", distiller.__version__)\n",
    "\n",
    "\n",
    "pylogger = PythonLogger(msglogger, log_1d=True)\n",
    "all_loggers = [pylogger]\n",
    "\n",
    "# tensorboard\n",
    "tflogger = TensorBoardLogger(msglogger.logdir, log_1d=True, comment='_'+dataset_name)\n",
    "\n",
    "tflogger.tblogger.writer.add_text('Command line', \"args ---\")\n",
    "\n",
    "msglogger.info('dataset_name:%s\\ndataset_fn=%s\\nnum_classes=%d\\nmodel_name=%s\\ndimensions=%s\\nbatch_size=%d\\nvalidation_split=%s\\nlr=%f',\n",
    "                dataset_name,dataset_fn,num_classes,model_name,dimensions,batch_size,validation_split,lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eadd17",
   "metadata": {},
   "source": [
    "## Create and Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd2047c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dogs': 0, 'cats': 1}\n",
      "{'dogs': 0, 'cats': 1}\n"
     ]
    }
   ],
   "source": [
    "args = Args(act_mode_8bit=False)\n",
    "train_set, test_set = cats_and_dogs_get_datasets((data_path, args), load_train=True, load_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cada0",
   "metadata": {},
   "source": [
    "## Visualize a batch of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c6b5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set.visualize_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b63d2a",
   "metadata": {},
   "source": [
    "## Create the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "196575ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "\ttraining=18000\n",
      "\tvalidation=2000\n",
      "\ttest=5000\n",
      "Augmentations:Compose(\n",
      "    Resize(size=(128, 128), interpolation=bilinear)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 5))\n",
      "    ToTensor()\n",
      "    <ai8x.normalize object at 0x7fd03873b910>\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dogs': 0, 'cats': 1}\n",
      "{'dogs': 0, 'cats': 1}\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, _ = apputils.get_data_loaders(\n",
    "        dataset_fn, (data_path,args), batch_size,\n",
    "        workers, validation_split, deterministic,1, 1, 1)\n",
    "msglogger.info('Dataset sizes:\\n\\ttraining=%d\\n\\tvalidation=%d\\n\\ttest=%d',\n",
    "                   len(train_loader.sampler), len(val_loader.sampler), len(test_loader.sampler))\n",
    "msglogger.info('Augmentations:%s',train_loader.dataset.transform)\n",
    "# train_dataloader = DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "# test_dataloader = DataLoader(test_set,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c934995",
   "metadata": {},
   "source": [
    "## Set up the device, cuda or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8dabe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e26d9",
   "metadata": {},
   "source": [
    "## Set up the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7db0732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=False.\n",
      "Number of Model Params: 279562\n"
     ]
    }
   ],
   "source": [
    "ai8x.set_device(device=85, simulate=False, round_avg=False)\n",
    "\n",
    "model = mod.CatsAndDogsClassifier()\n",
    "        \n",
    "model = model.to(device)\n",
    "\n",
    "print(f'Number of Model Params: {count_params(model)}')\n",
    "\n",
    "# configure tensorboard\n",
    "dummy_input = torch.randn((1, ) + dimensions)\n",
    "tflogger.tblogger.writer.add_graph(model.to('cpu'), (dummy_input, ), False)\n",
    "\n",
    "all_loggers.append(tflogger)\n",
    "all_tbloggers = [tflogger]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddad2c1",
   "metadata": {},
   "source": [
    "## Set up the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c00fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs: 40\n",
      "Optimizer Type: <class 'torch.optim.adam.Adam'>\n",
      "lr_schedule:base: [0.001] milestones: Counter({5: 1, 25: 1}) gamma: 0.5\n",
      "qat policy: {'start_epoch': 5, 'weight_bits': 8}\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "msglogger.info('epochs: %d',num_epochs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "msglogger.info('Optimizer Type: %s', type(optimizer))\n",
    "ms_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 25], gamma=0.5)\n",
    "msglogger.info(\"lr_schedule:%s\",\"base: \"+str(ms_lr_scheduler.base_lrs)+\" milestones: \"+str(ms_lr_scheduler.milestones)+ \" gamma: \"+str(ms_lr_scheduler.gamma))\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "qat_policy = {'start_epoch':5,\n",
    "              'weight_bits':8}\n",
    "msglogger.info('qat policy: %s',qat_policy)\n",
    "compression_scheduler = distiller.CompressionScheduler(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e446e",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ba442fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader, model, criterion, loggers, epoch=-1, tflogger=None):\n",
    "    \"\"\"Execute the validation/test loop.\"\"\"\n",
    "\n",
    "    # store loss stats\n",
    "    losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "    classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "\n",
    "    # validation set info\n",
    "    batch_time = tnt.AverageValueMeter()\n",
    "    total_samples = len(data_loader.sampler)\n",
    "    batch_size = data_loader.batch_size\n",
    "    confusion = tnt.ConfusionMeter(num_classes)\n",
    "    total_steps = (total_samples + batch_size - 1) // batch_size\n",
    "    msglogger.info('%d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    class_probs = []\n",
    "    class_preds = []\n",
    "\n",
    "    # iterate over the batches in the validation set\n",
    "    for validation_step, (inputs, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            inputs, target = inputs.to(device), target.to(device)\n",
    "            # compute output from model\n",
    "            output = model(inputs)\n",
    "            # correct output for accurate loss calculation\n",
    "            if args.act_mode_8bit:\n",
    "                output /= 128.\n",
    "                for key in model.__dict__['_modules'].keys():\n",
    "                    if (hasattr(model.__dict__['_modules'][key], 'wide')\n",
    "                            and model.__dict__['_modules'][key].wide):\n",
    "                        output /= 256.\n",
    "            # compute loss\n",
    "            loss = criterion(output, target)\n",
    "            # measure accuracy and record loss\n",
    "            losses['objective_loss'].add(loss.item())\n",
    "            if len(output.data.shape) <= 2:\n",
    "                classerr.add(output.data, target)\n",
    "            else:\n",
    "                classerr.add(output.data.permute(0, 2, 3, 1).flatten(start_dim=0, end_dim=2),\n",
    "                                target.flatten())\n",
    "            \n",
    "            confusion.add(output.data, target)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.add(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # store prediction stats\n",
    "            steps_completed = (validation_step+1)\n",
    "            if steps_completed % print_freq == 0 or steps_completed == total_steps:\n",
    "                class_probs_batch = [torch.nn.functional.softmax(el, dim=0) for el in output]\n",
    "                _, class_preds_batch = torch.max(output, 1)\n",
    "                class_probs.append(class_probs_batch)\n",
    "                class_preds.append(class_preds_batch)\n",
    "\n",
    "                stats = (\n",
    "                    '',\n",
    "                    OrderedDict([('Loss', losses['objective_loss'].mean),\n",
    "                                    ('Top1', classerr.value(1))])\n",
    "                )\n",
    "                if num_classes > 5:\n",
    "                    stats[1]['Top5'] = classerr.value(5)\n",
    "\n",
    "                distiller.log_training_progress(stats, None, epoch, steps_completed,\n",
    "                                                total_steps, print_freq, loggers)\n",
    "\n",
    "                # if tflogger is not None:\n",
    "                #     test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "                #     test_preds = torch.cat(class_preds)\n",
    "                #     for i in range(num_classes):\n",
    "                #         tb_preds = test_preds == i\n",
    "                #         tb_probs = test_probs[:, i]\n",
    "                #         tflogger.tblogger.writer.add_pr_curve(str(args.labels[i]), tb_preds,\n",
    "                #                                             tb_probs, global_step=epoch)\n",
    "\n",
    "                # if steps_completed == total_steps and tflogger is not None:\n",
    "                #     def select_n_random(data, labels, features, n=100):\n",
    "                #         \"\"\"Selects n random datapoints, their corresponding labels and features\"\"\"\n",
    "                #         assert len(data) == len(labels) == len(features)\n",
    "\n",
    "                #         perm = torch.randperm(len(data))\n",
    "                #         return data[perm][:n], labels[perm][:n], features[perm][:n]\n",
    "\n",
    "                #     # Select up to 100 random images and their target indices\n",
    "                #     images, labels, features = select_n_random(inputs, target, output,\n",
    "                #                                                n=min(100, len(inputs)))\n",
    "\n",
    "                #     # Get the class labels for each image\n",
    "                #     class_labels = [args.labels[lab] for lab in labels]\n",
    "\n",
    "                #     tflogger.tblogger.writer.add_embedding(\n",
    "                #         features,\n",
    "                #         metadata=class_labels,\n",
    "                #         label_img=args.visualize_fn(images, args),\n",
    "                #         global_step=epoch,\n",
    "                #         tag='verification/embedding'\n",
    "                #     )\n",
    "\n",
    "    if num_classes > 5:\n",
    "        msglogger.info('==> Top1: %.3f    Top5: %.3f    Loss: %.3f\\n',\n",
    "                        classerr.value()[0], classerr.value()[1],\n",
    "                        losses['objective_loss'].mean)\n",
    "    else:\n",
    "        msglogger.info('==> Top1: %.3f    Loss: %.3f\\n',\n",
    "                        classerr.value()[0], losses['objective_loss'].mean)\n",
    "\n",
    "    msglogger.info('==> Confusion:\\n%s\\n', str(confusion.value()))\n",
    "    if tflogger is not None:\n",
    "        cf = nnplot.confusion_matrix(confusion.value(), labels)\n",
    "        tflogger.tblogger.writer.add_image('Validation/ConfusionMatrix', cf, epoch,\n",
    "                                            dataformats='HWC')\n",
    "    return classerr.value(1), classerr.value(min(num_classes, 5)), losses['objective_loss'].mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92564625",
   "metadata": {},
   "source": [
    "## Run the trianing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1731f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 18000 samples (32 per mini-batch)\n",
      "/home/geffencooper/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "\n",
      "Epoch: [0][  100/  563]    objective_loss 0.692981                                        LR 0.000250    Time 0.023976    \n",
      "Epoch: [0][  200/  563]    objective_loss 0.690697                                        LR 0.000250    Time 0.022691    \n",
      "Epoch: [0][  300/  563]    objective_loss 0.689208                                        LR 0.000250    Time 0.022268    \n",
      "Epoch: [0][  400/  563]    objective_loss 0.689237                                        LR 0.000250    Time 0.022073    \n",
      "Epoch: [0][  500/  563]    objective_loss 0.689662                                        LR 0.000250    Time 0.021947    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=50'>51</a>\u001b[0m inputs, target \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=52'>53</a>\u001b[0m \u001b[39m# forward pass and loss calculation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=53'>54</a>\u001b[0m output \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=54'>55</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000019vscode-remote?line=56'>57</a>\u001b[0m \u001b[39m# on the last batch store the stats for the epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/models/cat-dog_net.py:80\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m def forward(self, x):  # pylint: disable=arguments-differ\n\u001b[1;32m     79\u001b[0m     \"\"\"Forward prop\"\"\"\n\u001b[0;32m---> 80\u001b[0m     x = self.conv1(x)\n\u001b[1;32m     81\u001b[0m     x = self.conv2(x)\n\u001b[1;32m     82\u001b[0m     x = self.conv3(x)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/ai8x.py:538\u001b[0m, in \u001b[0;36mQuantizationAwareModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    536\u001b[0m     params_r \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdetach())\n\u001b[1;32m    537\u001b[0m out_shift \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalc_out_shift(params_r, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_shift\u001b[39m.\u001b[39mdetach())\n\u001b[0;32m--> 538\u001b[0m weight_scale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_weight_scale(out_shift)\n\u001b[1;32m    539\u001b[0m out_scale \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalc_out_scale(out_shift)\n\u001b[1;32m    541\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_shift \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mParameter(out_shift\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/Model_Development/ai8x-training/ai8x.py:385\u001b[0m, in \u001b[0;36mOne.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):  \u001b[39m# pylint: disable=arguments-differ, no-self-use\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[39m\"\"\"Forward prop\"\"\"\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mones(\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# keep track of incorrect predictions\n",
    "wrong_samples = None\n",
    "wrong_preds = None\n",
    "actual_preds = None\n",
    "\n",
    "# store model history across epochs\n",
    "perf_scores_history = []\n",
    "model = model.to(device)\n",
    "\n",
    "name = model_name\n",
    "\n",
    "# training loop\n",
    "for epoch in range(0, num_epochs):\n",
    "    # check if need to switch to QAT\n",
    "    if epoch > 0 and epoch == qat_policy['start_epoch']:\n",
    "        print('QAT is starting!')\n",
    "        # Fuse the BN parameters into conv layers before Quantization Aware Training (QAT)\n",
    "        ai8x.fuse_bn_layers(model)\n",
    "\n",
    "        # Switch model from unquantized to quantized for QAT\n",
    "        ai8x.initiate_qat(model, qat_policy)\n",
    "\n",
    "        # Model is re-transferred to GPU in case parameters were added\n",
    "        model.to(device)\n",
    "\n",
    "        # Empty the performance scores list for QAT operation\n",
    "        perf_scores_history = []\n",
    "        name = f'{model_name}_qat'\n",
    "\n",
    "    # store loss and training stats\n",
    "    losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "    classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, min(num_classes, 5)))\n",
    "    batch_time = tnt.AverageValueMeter()\n",
    "    data_time = tnt.AverageValueMeter()\n",
    "\n",
    "    # logging stats\n",
    "    total_samples = len(train_loader.sampler)\n",
    "    batch_size = train_loader.batch_size\n",
    "    steps_per_epoch = (total_samples + batch_size - 1) // batch_size\n",
    "    msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "    acc_stats = []\n",
    "    end = time.time()\n",
    "\n",
    "    # iterate over all batches in the dataset\n",
    "    for train_step, (inputs, target) in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.add(time.time() - end)\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # on the last batch store the stats for the epoch\n",
    "        if train_step >= len(train_loader)-2:\n",
    "            if len(output.data.shape) <= 2:\n",
    "                classerr.add(output.data, target)\n",
    "            else:\n",
    "                classerr.add(output.data.permute(0, 2, 3, 1).flatten(start_dim=0, end_dim=2),\n",
    "                                target.flatten())\n",
    "            acc_stats.append([classerr.value(1), classerr.value(min(num_classes, 5))])\n",
    "\n",
    "        # add the loss for each batch\n",
    "        losses[\"objective_loss\"].add(loss.item())\n",
    "\n",
    "        # reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backwards pass and parameter update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # track batch stats\n",
    "        batch_time.add(time.time() - end)\n",
    "        steps_completed = (train_step+1)\n",
    "\n",
    "        # log stats every 10 batches\n",
    "        if steps_completed % print_freq == 0 or steps_completed == steps_per_epoch:\n",
    "            # Log some statistics\n",
    "            errs = OrderedDict()\n",
    "            if classerr.n != 0:\n",
    "                errs['Top1'] = classerr.value(1)\n",
    "                if num_classes > 5:\n",
    "                    errs['Top5'] = classerr.value(5)\n",
    "            else:\n",
    "                errs['Top1'] = None\n",
    "                errs['Top5'] = None\n",
    "\n",
    "            stats_dict = OrderedDict()\n",
    "            for loss_name, meter in losses.items():\n",
    "                stats_dict[loss_name] = meter.mean\n",
    "            stats_dict.update(errs)\n",
    "            \n",
    "            stats_dict['LR'] = optimizer.param_groups[0]['lr']\n",
    "            stats_dict['Time'] = batch_time.mean\n",
    "            stats = ('Performance/Training/', stats_dict)\n",
    "            params = None\n",
    "            distiller.log_training_progress(stats,\n",
    "                                            params,\n",
    "                                            epoch, steps_completed,\n",
    "                                            steps_per_epoch, print_freq,\n",
    "                                            all_loggers)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    # after a training epoch, do validation\n",
    "    msglogger.info('--- validate (epoch=%d)-----------', epoch)\n",
    "    top1, top5, vloss = validate(val_loader, model, criterion, [pylogger], epoch, tflogger)\n",
    "\n",
    "    # store validation stats\n",
    "    stats = ('Performance/Validation/', OrderedDict([('Loss', vloss), ('Top1', top1)]))\n",
    "    if num_classes > 5:\n",
    "        stats[1]['Top5'] = top5\n",
    "\n",
    "    distiller.log_training_progress(stats, None, epoch, steps_completed=0, total_steps=1,\n",
    "                                            log_freq=1, loggers=all_tbloggers)\n",
    "\n",
    "    perf_scores_history.append(distiller.MutableNamedTuple({'top1': top1, 'top5': top5,\n",
    "                                                            'epoch': epoch}))\n",
    "    # Keep perf_scores_history sorted from best to worst\n",
    "    # Sort by top1 as main sort key, then sort by top5 and epoch\n",
    "    perf_scores_history.sort(key=operator.attrgetter('top1', 'top5', 'epoch'),reverse=True)\n",
    "    for score in perf_scores_history[:1]:\n",
    "        if num_classes > 5:\n",
    "            msglogger.info('==> Best [Top1: %.3f   Top5: %.3f  on epoch: %d]',\n",
    "                            score.top1, score.top5,score.epoch)\n",
    "        else:\n",
    "            msglogger.info('==> Best [Top1: %.3f on epoch: %d]',\n",
    "                            score.top1, score.epoch)\n",
    "\n",
    "    # Save the checkpoint\n",
    "    is_best = epoch == perf_scores_history[0].epoch\n",
    "    checkpoint_extras = {'current_top1': top1,\n",
    "                        'best_top1': perf_scores_history[0].top1,\n",
    "                        'best_epoch': perf_scores_history[0].epoch}\n",
    "\n",
    "    apputils.save_checkpoint(epoch, model_name, model, optimizer=optimizer,\n",
    "                                scheduler=compression_scheduler, extras=checkpoint_extras,\n",
    "                                is_best=is_best, name=name,\n",
    "                                dir=msglogger.logdir)\n",
    "\n",
    "    ms_lr_scheduler.step()\n",
    "\n",
    "# Finally run results on the test set\n",
    "top1, top5, losses = validate(test_loader, model, criterion, [pylogger],epoch,None)\n",
    "msglogger.info('==> Best [Top1: %.3f   Top5: %.3f  on test set]', top1, top5)\n",
    "\n",
    "\n",
    "\n",
    "#     running_loss = []\n",
    "#     train_start = time.time()\n",
    "#     model.train()\n",
    "#     for idx, (image, label) in enumerate(train_dataloader):\n",
    "#         image = image.to(device)\n",
    "#         label = label.type(torch.long).to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         model_out = model(image)\n",
    "        \n",
    "#         loss = criterion(model_out, label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "#     mean_loss = np.mean(running_loss)\n",
    "#     train_end = time.time()\n",
    "#     print(\"Epoch: {}/{}\\t LR: {}\\t Train Loss: {:.4f}\\t Dur: {:.2f} sec.\".format(epoch+1, num_epochs, ms_lr_scheduler.get_lr(), mean_loss, (train_end-train_start)))\n",
    "    \n",
    "#     model.eval()\n",
    "#     acc = 0.\n",
    "#     acc_weight = 0\n",
    "#     with torch.no_grad():\n",
    "#         for image, label in test_dataloader:\n",
    "#             image = image.to(device)\n",
    "#             label = label.type(torch.long).to(device)\n",
    "#             model_out = model(image)\n",
    "#             label_out = torch.argmax(model_out, dim=1)\n",
    "\n",
    "#             # display wrong outputs\n",
    "#             pred = model_out.argmax(dim=1, keepdim=True) # get the idxs of the max output\n",
    "#             wrong_idx = (pred != label.view_as(pred)).nonzero()[:, 0] # get wrong predictions\n",
    "#             wrong_samples = image[wrong_idx]\n",
    "#             wrong_preds = pred[wrong_idx]\n",
    "#             actual_preds = label.view_as(pred)[wrong_idx]\n",
    "            \n",
    "#             # test_set.viz_mispredict(wrong_samples,wrong_preds,actual_preds)\n",
    "            \n",
    "#             tp = torch.sum(label_out == label)\n",
    "#             acc_batch = (tp / label_out.numel()).detach().item()\n",
    "#             acc += label_out.shape[0] * acc_batch\n",
    "#             acc_weight += label_out.shape[0]\n",
    "            \n",
    "#         total_acc = 100 * (acc / acc_weight)\n",
    "#         if epoch == qat_policy['start_epoch']: best_acc = 0\n",
    "#         if total_acc > best_acc:\n",
    "#             best_acc = total_acc\n",
    "#             checkpoint_extras = {'current_top1': best_acc,\n",
    "#                                  'best_top1': best_acc,\n",
    "#                                  'best_epoch': epoch}\n",
    "#             model_name = 'catdognet'\n",
    "#             model_prefix = f'{model_name}' if epoch < qat_policy['start_epoch'] else (f'qat_{model_name}')\n",
    "#             apputils.save_checkpoint(epoch, model_name, model, optimizer=optimizer,\n",
    "#                                      scheduler=None, extras=checkpoint_extras,\n",
    "#                                      is_best=True, name=model_prefix,\n",
    "#                                      dir='.')\n",
    "#             print(f'Best model saved with accuracy: {best_acc:.2f}%')\n",
    "            \n",
    "#         print('\\t\\t Test Acc: {:.2f}'.format(total_acc))\n",
    "        \n",
    "#     ms_lr_scheduler.step()\n",
    "# #test_set.visualize_batch(model,device)\n",
    "# test_set.viz_mispredict(wrong_samples,wrong_preds,actual_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eaab8",
   "metadata": {},
   "source": [
    "## Quantize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed081a7",
   "metadata": {},
   "source": [
    "You must change the kernel to execute within the ai8x-synthesis virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed6b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000\n",
      "Converting checkpoint file jupyter_logging/train_log___2022.06.21-165010/cat-dog_net_qat_best.pth.tar to jupyter_logging/train_log___2022.06.21-165010/cat-dog_net_qat_best-q.pth.tar\n",
      "\n",
      "Model keys (state_dict):\n",
      "conv1.output_shift, conv1.weight_bits, conv1.bias_bits, conv1.quantize_activation, conv1.adjust_output_shift, conv1.shift_quantile, conv1.op.weight, conv2.output_shift, conv2.weight_bits, conv2.bias_bits, conv2.quantize_activation, conv2.adjust_output_shift, conv2.shift_quantile, conv2.op.weight, conv3.output_shift, conv3.weight_bits, conv3.bias_bits, conv3.quantize_activation, conv3.adjust_output_shift, conv3.shift_quantile, conv3.op.weight, conv4.output_shift, conv4.weight_bits, conv4.bias_bits, conv4.quantize_activation, conv4.adjust_output_shift, conv4.shift_quantile, conv4.op.weight, conv4.op.bias, conv5.output_shift, conv5.weight_bits, conv5.bias_bits, conv5.quantize_activation, conv5.adjust_output_shift, conv5.shift_quantile, conv5.op.weight, conv5.op.bias, conv6.output_shift, conv6.weight_bits, conv6.bias_bits, conv6.quantize_activation, conv6.adjust_output_shift, conv6.shift_quantile, conv6.op.weight, conv6.op.bias, conv7.output_shift, conv7.weight_bits, conv7.bias_bits, conv7.quantize_activation, conv7.adjust_output_shift, conv7.shift_quantile, conv7.op.weight, conv7.op.bias, conv8.output_shift, conv8.weight_bits, conv8.bias_bits, conv8.quantize_activation, conv8.adjust_output_shift, conv8.shift_quantile, conv8.op.weight, conv8.op.bias, conv9.output_shift, conv9.weight_bits, conv9.bias_bits, conv9.quantize_activation, conv9.adjust_output_shift, conv9.shift_quantile, conv9.op.weight, conv9.op.bias, conv10.output_shift, conv10.weight_bits, conv10.bias_bits, conv10.quantize_activation, conv10.adjust_output_shift, conv10.shift_quantile, conv10.op.weight, conv10.op.bias, fc1.output_shift, fc1.weight_bits, fc1.bias_bits, fc1.quantize_activation, fc1.adjust_output_shift, fc1.shift_quantile, fc1.op.weight, fc1.op.bias, fc2.output_shift, fc2.weight_bits, fc2.bias_bits, fc2.quantize_activation, fc2.adjust_output_shift, fc2.shift_quantile, fc2.op.weight, fc2.op.bias\n",
      "conv1.op.weight avg_max: 0.4327472 max: 0.56188697 mean: -0.0027538533 factor: [128.] bits: 8\n",
      "conv2.op.weight avg_max: 0.42334658 max: 0.54720956 mean: 0.0077749672 factor: [128.] bits: 8\n",
      "conv3.op.weight avg_max: 0.3699992 max: 0.5655854 mean: -0.018680878 factor: [128.] bits: 8\n",
      "conv4.op.weight avg_max: 0.68629307 max: 0.8760979 mean: -0.02834613 factor: [128.] bits: 8\n",
      "conv4.op.bias avg_max: 0.06927104 max: 0.2845439 mean: 0.06927104 factor: [128.] bits: 8\n",
      "conv5.op.weight avg_max: 0.3720157 max: 0.49573195 mean: -0.01598631 factor: [256.] bits: 8\n",
      "conv5.op.bias avg_max: 0.069569394 max: 0.30960843 mean: 0.069569394 factor: [256.] bits: 8\n",
      "conv6.op.weight avg_max: 0.35553867 max: 0.5092938 mean: -0.026748905 factor: [128.] bits: 8\n",
      "conv6.op.bias avg_max: 0.064387925 max: 0.43863288 mean: 0.064387925 factor: [128.] bits: 8\n",
      "conv7.op.weight avg_max: 0.30614784 max: 0.45207092 mean: -0.018534554 factor: [128.] bits: 8\n",
      "conv7.op.bias avg_max: 0.014573285 max: 0.57933074 mean: -0.014573285 factor: [128.] bits: 8\n",
      "conv8.op.weight avg_max: 0.3014418 max: 0.44312754 mean: -0.024422325 factor: [256.] bits: 8\n",
      "conv8.op.bias avg_max: 0.08743416 max: 0.38885924 mean: 0.08743416 factor: [256.] bits: 8\n",
      "conv9.op.weight avg_max: 0.21891764 max: 0.43148714 mean: -0.010214452 factor: [256.] bits: 8\n",
      "conv9.op.bias avg_max: 0.12192847 max: 0.43849126 mean: -0.12192847 factor: [256.] bits: 8\n",
      "conv10.op.weight avg_max: 0.21212819 max: 0.37051785 mean: -0.009067744 factor: [256.] bits: 8\n",
      "conv10.op.bias avg_max: 0.06728599 max: 0.36591044 mean: -0.06728599 factor: [256.] bits: 8\n",
      "fc1.op.weight avg_max: 0.24611649 max: 0.4571888 mean: -0.0054269163 factor: [256.] bits: 8\n",
      "fc1.op.bias avg_max: 0.020117387 max: 0.098327585 mean: -0.020117387 factor: [256.] bits: 8\n",
      "fc2.op.weight avg_max: 0.5395457 max: 0.5818031 mean: 0.0025900025 factor: [128.] bits: 8\n",
      "fc2.op.bias avg_max: 0.026644157 max: 0.08697507 mean: 0.026644157 factor: [128.] bits: 8\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run ../ai8x-synthesis/quantize.py jupyter_logging/train_log___2022.06.21-165010/cat-dog_net_qat_best.pth.tar jupyter_logging/train_log___2022.06.21-165010/cat-dog_net_qat_best-q.pth.tar --device MAX78000 -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1681a",
   "metadata": {},
   "source": [
    "## Evaluate Quantized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216527c",
   "metadata": {},
   "source": [
    "Change virtual environment back to ai8x-training and rerun the first cell with the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67b162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "\n",
    "try:\n",
    "    import tensorboard  # pylint: disable=import-error\n",
    "    import tensorflow  # pylint: disable=import-error\n",
    "    tensorflow.io.gfile = tensorboard.compat.tensorflow_stub.io.gfile\n",
    "except (ModuleNotFoundError, AttributeError):\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchnet.meter as tnt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import nnplot\n",
    "import operator\n",
    "import distiller\n",
    "import distiller.apputils as apputils\n",
    "from distiller.data_loggers import PythonLogger, TensorBoardLogger\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'models/')\n",
    "sys.path.insert(1, 'distiller/')\n",
    "sys.path.insert(2, 'datasets/')\n",
    "\n",
    "from cats_and_dogs import *\n",
    "\n",
    "mod = importlib.import_module(\"cat-dog_net\")\n",
    "\n",
    "import ai8x\n",
    "%matplotlib inline\n",
    "\n",
    "# Logger handle\n",
    "msglogger = None\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, act_mode_8bit):\n",
    "        self.act_mode_8bit = act_mode_8bit\n",
    "        self.truncate_testset = False\n",
    "\n",
    "def count_params(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b61e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring device: MAX78000, simulate=True.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "load_model_path = 'jupyter_logging/train_log___2022.06.21-165010/cat-dog_net_qat_best-q.pth.tar'\n",
    "# Change this path to match file system layout\n",
    "data_path = \"../Datasets/cats_and_dogs/\"\n",
    "\n",
    "ai8x.set_device(device=85, simulate=True, round_avg=False)\n",
    "\n",
    "model = mod.CatsAndDogsClassifier()\n",
    "                          \n",
    "checkpoint = torch.load(load_model_path, map_location=lambda storage, loc: storage)\n",
    "ai8x.fuse_bn_layers(model)\n",
    "model = apputils.load_lean_checkpoint(model, load_model_path, model_device=device)\n",
    "ai8x.update_model(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a04b5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dogs': 0, 'cats': 1}\n",
      "{'dogs': 0, 'cats': 1}\n"
     ]
    }
   ],
   "source": [
    "args = Args(act_mode_8bit=True)\n",
    "\n",
    "_, test_set = train_set, test_set = cats_and_dogs_get_datasets((data_path, args), load_train=True, load_test=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ccce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized accuracy: 89.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "acc = 0.\n",
    "acc_weight = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_dataloader:\n",
    "        image = image.to(device)\n",
    "        label = label.type(torch.long).to(device)\n",
    "        model_out = model(image)\n",
    "        label_out = torch.argmax(model_out, dim=1)\n",
    "\n",
    "        tp = torch.sum(label_out == label)\n",
    "        acc_batch = (tp / label_out.numel()).detach().item()\n",
    "        acc += label_out.shape[0] * acc_batch\n",
    "        acc_weight += label_out.shape[0]\n",
    "\n",
    "    total_acc = 100 * (acc / acc_weight)\n",
    "print(f'Quantized accuracy: {total_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30edf601",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000022vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m image, label \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000022vscode-remote?line=1'>2</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdesktop_workstation/home/geffencooper/Model_Development/ai8x-training/Cats_and_Dogs.ipynb#ch0000022vscode-remote?line=3'>4</a>\u001b[0m im_sample \u001b[39m=\u001b[39m (image[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for image, label in test_dataloader:\n",
    "    break\n",
    "\n",
    "im_sample = (image[0].detach().cpu().numpy()).astype(np.int64)\n",
    "\n",
    "np.save('sample_cats_and_dogs.npy', im_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa74c1",
   "metadata": {},
   "source": [
    "## Model Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffee381f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Storing weights...   <span style=\"color: #f92672; text-decoration-color: #f92672\"></span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"></span> <span style=\"color: #800080; text-decoration-color: #800080\"> 84%</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Storing weights...   \u001b[38;2;249;38;114m\u001b[0m\u001b[38;2;249;38;114m\u001b[0m\u001b[38;5;237m\u001b[0m \u001b[35m 84%\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997bf14482984e80a46372631220d46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING:</span> </pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING:\u001b[0m "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 1: All output values for the given sample input are zero. The generated known-answer test for this network may not be meaningful. See the log file for details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING:</span> </pre>\n"
      ],
      "text/plain": [
       "\u001b[33mWARNING:\u001b[0m "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd ../ai8x-synthesis/\n",
    "%run ai8xize.py --verbose --log --test-dir sdk/Examples/MAX78000/CNN --prefix cats_and_dogs --checkpoint-file ../ai8x-training/jupyter_logging/train_log___2022.06.21-165010/cat-dog_net_qat_best-q.pth.tar --config-file networks/cats_and_dogs.yaml --device MAX78000 --softmax --compact-data --mexpress --timer 0 --fifo --display-checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai8x-training",
   "language": "python",
   "name": "ai8x-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
